{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where is the limit?\n",
    "In this notebook we evaluate the model for classifying images into TC or x-TC. With this we seek to discover which is the boundary between both phenomena according to the model. We hope this can shed some light on the process of discerning between these events, as it is usually a subjective human decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "from os.path import join\n",
    "import json\n",
    "\n",
    "from pyphoon.db.pd_manager import PDManager\n",
    "from pyphoon.db.data_extractor import DataExtractor\n",
    "from pyphoon.app.preprocess import DefaultImagePreprocessor\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which sequences?\n",
    "Not all sequences serve the purpose of evaluating how good our model is performing. We make sure that any sequence used here belongs either to the training set or the validation set. We want to avoid using any test data as a source of feedback to improve our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../tasks/tcxtc/traintest_split_tcxtc.json') as f:\n",
    "    info = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now select a typhoon sequence from the validation set.\n",
    "\n",
    "**Note**: Interesting sequences are: 199906, 201711, 200306, which contain both TC and xTC sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Typhoon selected: 201524\n"
     ]
    }
   ],
   "source": [
    "# Pick sequence\n",
    "import random\n",
    "seq_no = random.sample(info['valid'], 1)[0]\n",
    "print(\"Typhoon selected:\", seq_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sequence\n",
    "Let us load a sequence from the original dataset (well, actually we use the corrected version). To this end, we will first create a `PDManager` object, which is the bridge to the dataset. Using this object, we will define a `DataExtractor` which will allow us to extract, for instance, a specific typhoon sequence given its sequence number. In addition, we need to define a Preprocessor, such that the data is loaded to be suitable for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to source data\n",
    "orig_images_dir = '/root/fs9/datasets/typhoon/wnp/image/'\n",
    "besttrack_dir = '/root/fs9/datasets/typhoon/wnp/jma'\n",
    "\n",
    "# Path where corrected images are to be stored\n",
    "corrected_dir = '/root/fs9/grishin/database/corrected'\n",
    "\n",
    "# Path to new database files\n",
    "db_dir = '/root/fs9/grishin/database'\n",
    "# Pickle files (used to store dataframes)\n",
    "images_pkl_path = join(db_dir, 'images.pkl')\n",
    "corrected_pkl_path = join(db_dir, 'corrected.pkl')\n",
    "besttrack_pkl_path = join(db_dir, 'besttrack.pkl')\n",
    "missing_pkl_path = join(db_dir, 'missing.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pd_man\n",
    "man = PDManager()\n",
    "man.load_original_images(images_pkl_path)\n",
    "man.load_besttrack(besttrack_pkl_path)\n",
    "man.load_corrected_images(corrected_pkl_path)\n",
    "\n",
    "#Â Preprocess algorithm\n",
    "preprocessor = DefaultImagePreprocessor(mean=269.15, std=24.14, resize_factor=2, reshape_mode='keras')\n",
    "\n",
    "# Define data extractor\n",
    "de = DataExtractor(original_images_dir=orig_images_dir, corrected_images_dir=corrected_dir, pd_manager=man)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, images_ids, features = de.read_seq(seq_no, preprocessor.apply, ['class'])\n",
    "X = np.array(images)\n",
    "Y = ground_truth = [0 if label != 6 else 1 for label in features['class'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:\n",
      " * TC: 223\n",
      " * x-TC: 0\n"
     ]
    }
   ],
   "source": [
    "# Number Typhoon class distribution\n",
    "print(\"Number of samples:\")\n",
    "print(\" * TC:\", sum([1 for label in Y if label == 0]))\n",
    "print(\" * x-TC:\", sum([1 for label in Y if label == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = load_model('../../tasks/tcxtc/model_tcxtc_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model has been loaded, time to obtain the predictions on the loaded chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95       223\n",
      "          1       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.90      0.95       223\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Get complete report\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict_classes(X)\n",
    "print(classification_report(Y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
