{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to be the baseline for loading and training models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/root/projects/pyphoon/')\n",
    "from os.path import join\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import h5py\n",
    "import gc\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "from pyphoon.app.utils import load_h5datachunks\n",
    "from pyphoon.app.preprocess import MeanImagePreprocessor\n",
    "\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, \\\n",
    "    Flatten, Activation, Reshape, Dropout, add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have decided to use the following split:\n",
    "- Test: chunks 0-10\n",
    "- Validation: chunks 10-20\n",
    "- Training: chunks 20-end\n",
    "\n",
    "Note that this split must be preserved since preprocessing parameters have been computed on the training chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths where data is stored\n",
    "dataset_dir = '/root/fs9/lucas/data/datasets/task_2b/'\n",
    "chunk_filenames = listdir(dataset_dir)\n",
    "test_chunk_filenames = chunk_filenames[:10]\n",
    "valid_chunk_filenames = chunk_filenames[10:20]\n",
    "train_chunk_filenames = chunk_filenames[20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task, we will ignore classes 6 and 7 and only focus on Tropical Cyclones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " file 0_chunk.h5 read\n",
      " file 1_chunk.h5 read\n",
      " file 2_chunk.h5 read\n",
      " file 3_chunk.h5 read\n",
      " file 4_chunk.h5 read\n",
      " file 5_chunk.h5 read\n",
      " file 6_chunk.h5 read\n",
      " file 7_chunk.h5 read\n",
      " file 8_chunk.h5 read\n",
      " file 9_chunk.h5 read\n",
      " file 10_chunk.h5 read\n",
      " file 11_chunk.h5 read\n",
      " file 12_chunk.h5 read\n",
      " file 13_chunk.h5 read\n",
      " file 14_chunk.h5 read\n",
      " file 15_chunk.h5 read\n",
      " file 16_chunk.h5 read\n",
      " file 17_chunk.h5 read\n",
      " file 18_chunk.h5 read\n",
      " file 19_chunk.h5 read\n",
      " file 20_chunk.h5 read\n",
      " file 21_chunk.h5 read\n",
      " file 22_chunk.h5 read\n",
      " file 23_chunk.h5 read\n",
      " file 24_chunk.h5 read\n",
      " file 25_chunk.h5 read\n",
      " file 26_chunk.h5 read\n",
      " file 27_chunk.h5 read\n",
      " file 28_chunk.h5 read\n",
      " file 29_chunk.h5 read\n",
      " file 30_chunk.h5 read\n",
      " file 31_chunk.h5 read\n",
      " file 32_chunk.h5 read\n",
      " file 33_chunk.h5 read\n",
      " file 34_chunk.h5 read\n",
      " file 35_chunk.h5 read\n",
      " file 36_chunk.h5 read\n",
      " file 37_chunk.h5 read\n",
      " file 38_chunk.h5 read\n",
      " file 39_chunk.h5 read\n",
      " file 40_chunk.h5 read\n",
      " file 41_chunk.h5 read\n",
      " file 42_chunk.h5 read\n",
      " file 43_chunk.h5 read\n",
      " file 44_chunk.h5 read\n",
      " file 45_chunk.h5 read\n",
      " file 46_chunk.h5 read\n",
      " file 47_chunk.h5 read\n"
     ]
    }
   ],
   "source": [
    "X_test, Y_test = load_h5datachunks(dataset_dir, \n",
    "                                     test_chunk_filenames, \n",
    "                                     features=['data', 'class'],\n",
    "                                     ignore_classes=[6, 7],\n",
    "                                     display=True\n",
    "                                     )\n",
    "\n",
    "X_valid, Y_valid = load_h5datachunks(dataset_dir, \n",
    "                                     valid_chunk_filenames, \n",
    "                                     features=['data', 'class'],\n",
    "                                     ignore_classes=[6, 7],\n",
    "                                     display=True\n",
    "                                     )\n",
    "\n",
    "X_train, Y_train = load_h5datachunks(dataset_dir, \n",
    "                                     train_chunk_filenames, \n",
    "                                     features=['data', 'class'],\n",
    "                                     ignore_classes=[6, 7],\n",
    "                                     display=True\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task, we will use `MeanImagePreprocessor`, which uses the dataset mean image to centre the data and the minimum and maximum pixel values to normalise the images. To this end, we have previously computed these parameters and stored them under file `random.h5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessor\n",
    "with h5py.File('../../tasks/multiclass/preprocessing_random.h5') as f:\n",
    "    mean = f.get('mean_128').value\n",
    "    scale_factor = f.get('max_value_128').value - f.get('min_value_128').value\n",
    "preprocessor = MeanImagePreprocessor(mean, scale_factor, (128,128), 'keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "n = len(X_train)\n",
    "X_train = [np.expand_dims(preprocessor.apply(X_train[i][:,:,:,0]), axis=3) for i in range(n)]\n",
    "n = len(X_valid)\n",
    "X_valid = [np.expand_dims(preprocessor.apply(X_valid[i][:,:,:,0]), axis=3) for i in range(n)]\n",
    "n = len(X_test)\n",
    "X_test = [np.expand_dims(preprocessor.apply(X_test[i][:,:,:,0]), axis=3) for i in range(n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task we use standard conv nets with ReLU activation, Batch Norm, Max pooling and Dropout in first dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(128, 128, 1), name=\"in\")\n",
    "\n",
    "# Conv layers\n",
    "x = Conv2D(64, (3, 3), strides=(1, 1), padding='same', name='conv1')(\n",
    "    input_img)\n",
    "x = Activation('relu', name='act1')(x)\n",
    "x = BatchNormalization(name=\"bn1\")(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='pool1')(x)\n",
    "\n",
    "x = Conv2D(128, (3, 3), strides=(1, 1), padding='same', name='conv2')(x)\n",
    "x = Activation('relu', name='act2')(x)\n",
    "x = BatchNormalization(name=\"bn2\")(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='pool2')(x)\n",
    "\n",
    "x = Conv2D(128, (3, 3), strides=(1, 1), padding='same', name='conv3')(x)\n",
    "x = Activation('relu', name='act3')(x)\n",
    "x = BatchNormalization(name=\"bn3\")(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='pool3')(x)\n",
    "\n",
    "x = Conv2D(256, (3, 3), strides=(1, 1), padding='same', name='conv4')(x)\n",
    "x = Activation('relu', name='act4')(x)\n",
    "x = BatchNormalization(name=\"bn4\")(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='pool4')(x)\n",
    "\n",
    "x = Conv2D(256, (3, 3), strides=(1, 1), padding='same', name='conv5')(x)\n",
    "x = Activation('relu', name='act5')(x)\n",
    "x = BatchNormalization(name=\"bn5\")(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='pool5')(x)\n",
    "\n",
    "# Dense layers\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(1024, use_bias=True, name=\"fc1\")(x)\n",
    "x = Activation('relu', name=\"fc_act1\")(x)\n",
    "x = BatchNormalization(name=\"fc_bn1\")(x)\n",
    "x = Dropout(0.2, name=\"drop1\")(x)\n",
    "\n",
    "x = Dense(256, use_bias=True, name=\"fc2\")(x)\n",
    "x = Activation('relu', name=\"fc_act2\")(x)\n",
    "x = BatchNormalization(name=\"fc_bn2\")(x)\n",
    "\n",
    "# Out\n",
    "x = Dense(4, use_bias=True, name=\"fc4\")(x)\n",
    "x = Activation('softmax', name=\"out\")(x)\n",
    "\n",
    "# Model\n",
    "model = Model(input_img, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "in (InputLayer)              (None, 128, 128, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 128, 128, 64)      640       \n",
      "_________________________________________________________________\n",
      "act1 (Activation)            (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "act2 (Activation)            (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "act3 (Activation)            (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "act4 (Activation)            (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "act5 (Activation)            (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "bn5 (BatchNormalization)     (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling2D)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "fc_act1 (Activation)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc_bn1 (BatchNormalization)  (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "drop1 (Dropout)              (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "fc_act2 (Activation)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc_bn2 (BatchNormalization)  (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "out (Activation)             (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 5,574,532\n",
      "Trainable params: 5,570,308\n",
      "Non-trainable params: 4,224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\n",
    "    'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define two main callbacks:\n",
    "\n",
    "- Tensorboard: To monitor loss/accuracy curves.\n",
    "- Model storing: We store the model everytime validation loss is improved.\n",
    "\n",
    "To access Tensorboard visualisations, while training, execute\n",
    "\n",
    "$ tensorboard --logdir=<path/to/log-directory> --port <port>\n",
    "```\n",
    "\n",
    "seting `<path/to/log-directory>` to be the variable `tensorboard_path` defined below. Then navigate to `localhost:<port>`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "\n",
    "# Tensorboard\n",
    "use_tensorboard = True\n",
    "tensorboard_path = '/tmp/multiclass_rnd2'\n",
    "if use_tensorboard:\n",
    "    callbacks.append(TensorBoard(log_dir=tensorboard_path, histogram_freq=0,\n",
    "                                 write_graph=True, write_images=True))\n",
    "\n",
    "# Save model\n",
    "filepath = \"models_rnd2/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "m_cp = ModelCheckpoint(filepath, monitor='val_loss', verbose=0,\n",
    "                       save_best_only=True, save_weights_only=False,\n",
    "                       mode='auto', period=1)\n",
    "\n",
    "callbacks.append(m_cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train our model using data generators. In particular, we will feed our network with image batches from our lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator_from_chunklist(X, Y, batch_sz):\n",
    "    \"\"\" Generates batches of data from samples **X** and labels **Y**.\n",
    "\n",
    "    :param X: Sample data.\n",
    "    :type X: list\n",
    "    :param Y: Label data.\n",
    "    :type Y: list\n",
    "    :param batch_sz: Batch size.\n",
    "    :type batch_sz: int\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    n_chunks = len(X)\n",
    "    indices = list(range(n_chunks))\n",
    "\n",
    "    chunk_count = 0\n",
    "    while True:\n",
    "        # Randomise chunk order once all chunks have been seen\n",
    "        if chunk_count % n_chunks == 0:\n",
    "            np.random.shuffle(indices)\n",
    "\n",
    "        # Get chunk for batch generation\n",
    "        idx = indices[chunk_count % n_chunks]\n",
    "        _X = X[idx]\n",
    "        _Y = Y[idx]\n",
    "        # Shuffle batch data\n",
    "        n_samples = len(_Y)\n",
    "        pos = np.arange(n_samples)\n",
    "        np.random.shuffle(pos)\n",
    "        _X = _X[pos]\n",
    "        _Y = _Y[pos]\n",
    "        _Y = np_utils.to_categorical(_Y - 2, num_classes=4)\n",
    "\n",
    "        # Generate batches\n",
    "        imax = int(n_samples / batch_sz)\n",
    "        for i in range(imax):\n",
    "            # Find list of IDs\n",
    "            x = _X[i * batch_sz:(i + 1) * batch_sz]\n",
    "            y = _Y[i * batch_sz:(i + 1) * batch_sz]\n",
    "            yield x, y\n",
    "        chunk_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2617/2617 [==============================] - 193s 74ms/step - loss: 0.9145 - acc: 0.5996 - val_loss: 0.8490 - val_acc: 0.6235\n",
      "Epoch 2/15\n",
      "2617/2617 [==============================] - 190s 73ms/step - loss: 0.7012 - acc: 0.6987 - val_loss: 0.6901 - val_acc: 0.7300\n",
      "Epoch 3/15\n",
      "2617/2617 [==============================] - 190s 73ms/step - loss: 0.5482 - acc: 0.7763 - val_loss: 0.4961 - val_acc: 0.8025\n",
      "Epoch 4/15\n",
      "2617/2617 [==============================] - 190s 73ms/step - loss: 0.3930 - acc: 0.8471 - val_loss: 0.3993 - val_acc: 0.8497\n",
      "Epoch 5/15\n",
      "2617/2617 [==============================] - 187s 71ms/step - loss: 0.2789 - acc: 0.8948 - val_loss: 0.4316 - val_acc: 0.8428\n",
      "Epoch 6/15\n",
      "2617/2617 [==============================] - 187s 71ms/step - loss: 0.2159 - acc: 0.9208 - val_loss: 0.4166 - val_acc: 0.8537\n",
      "Epoch 7/15\n",
      "2617/2617 [==============================] - 190s 72ms/step - loss: 0.1726 - acc: 0.9385 - val_loss: 0.3130 - val_acc: 0.8973\n",
      "Epoch 8/15\n",
      "2617/2617 [==============================] - 190s 73ms/step - loss: 0.1499 - acc: 0.9461 - val_loss: 0.2955 - val_acc: 0.9028\n",
      "Epoch 9/15\n",
      "2616/2617 [============================>.] - ETA: 0s - loss: 0.1310 - acc: 0.9534"
     ]
    }
   ],
   "source": [
    "# Number train samples\n",
    "n_train = sum([len(x) for x in Y_train])  # 50000\n",
    "n_valid = sum([len(x) for x in Y_valid])\n",
    "\n",
    "# Number of full epochs, i.e. #times algorithm sees all the data\n",
    "epochs = 15\n",
    "batch_size = 32\n",
    "\n",
    "# Train\n",
    "model.fit_generator(\n",
    "    generator=data_generator_from_chunklist(X_train, Y_train,\n",
    "                                            batch_sz=batch_size),\n",
    "    steps_per_epoch=n_train // batch_size,\n",
    "    validation_data=data_generator_from_chunklist(X_valid, Y_valid,\n",
    "                                                  batch_sz=batch_size),\n",
    "    validation_steps=n_valid // batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "Below we obtain the confusion matrix from the estimations on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "cm = None\n",
    "for i in range(len(Y_valid)):\n",
    "    y_true = Y_valid[i] - 2\n",
    "    y_pred = model.predict(X_valid[i])\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    if cm is None:\n",
    "        cm = pd.crosstab(y_true, y_pred, rownames=['True'], colnames=['Predicted'], margins=True).as_matrix()\n",
    "    else:\n",
    "        cm += pd.crosstab(y_true, y_pred, rownames=['True'], colnames=['Predicted'], margins=True).as_matrix()\n",
    "    print(i) if i%3==0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision\n",
    "*How many true \"X\" were estimated to be \"X\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.43786655e-01   5.07911918e-02   4.42624765e-03   9.95905721e-04\n",
      "   1.00000000e+00]\n",
      "[ 0.05625242  0.89965085  0.03750162  0.00659511  1.        ]\n",
      "[ 0.01537905  0.07074362  0.86556902  0.0483083   1.        ]\n",
      "[ 0.00148351  0.00958576  0.03571836  0.95321237  1.        ]\n",
      "[ 0.29175789  0.25405666  0.17472634  0.27945911  1.        ]\n"
     ]
    }
   ],
   "source": [
    "for c in (cm.T/cm[:,-1]).T:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall\n",
    "*From the estimated \"X\", how many are actually true \"X\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.94118296,  0.05816753,  0.00737055,  0.00103687,  0.29095299],\n",
       "       [ 0.04800265,  0.88163731,  0.05343652,  0.00587558,  0.24896974],\n",
       "       [ 0.00937983,  0.04955012,  0.88151833,  0.03076037,  0.17794591],\n",
       "       [ 0.00143456,  0.01064504,  0.05767459,  0.96232719,  0.28213136],\n",
       "       [ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm/cm[-1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.28513007185556299, 0.92177835051546386]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_test = sum([len(x) for x in Y_test])\n",
    "\n",
    "model.evaluate_generator(\n",
    "    generator=data_generator_from_chunklist(X_test, Y_test,\n",
    "                                            batch_sz=batch_size),\n",
    "    steps=n_test // batch_size\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
